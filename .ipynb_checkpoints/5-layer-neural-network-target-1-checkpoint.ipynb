{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Task\n",
    "- Initially i dived in blind into building a neural network for my data for target-1, i used 5 layers with 12,50,26,12,1 nodes respectively.\n",
    "- I thought this would result in a good network,but much to my surprise the resultant MSE and Predictions were not satisfactory.\n",
    "- The activation fucntion i have used is Sigmoid function.\n",
    "- I have dropped features 8,11,6,13 based on benchmark notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vineeth\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.138</td>\n",
       "      <td>3.0</td>\n",
       "      <td>289.964</td>\n",
       "      <td>1349.489</td>\n",
       "      <td>6677.380</td>\n",
       "      <td>7.584</td>\n",
       "      <td>7.584</td>\n",
       "      <td>464.006</td>\n",
       "      <td>288.0</td>\n",
       "      <td>550.563</td>\n",
       "      <td>1.096</td>\n",
       "      <td>0.998</td>\n",
       "      <td>5.947</td>\n",
       "      <td>1.019</td>\n",
       "      <td>7.137</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.088</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6960.180</td>\n",
       "      <td>1376.166</td>\n",
       "      <td>6828.469</td>\n",
       "      <td>28.204</td>\n",
       "      <td>28.204</td>\n",
       "      <td>635.401</td>\n",
       "      <td>288.0</td>\n",
       "      <td>581.658</td>\n",
       "      <td>1.331</td>\n",
       "      <td>0.998</td>\n",
       "      <td>7.282</td>\n",
       "      <td>1.019</td>\n",
       "      <td>10.655</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.144</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8379.229</td>\n",
       "      <td>1386.757</td>\n",
       "      <td>7111.811</td>\n",
       "      <td>60.358</td>\n",
       "      <td>60.358</td>\n",
       "      <td>606.002</td>\n",
       "      <td>288.0</td>\n",
       "      <td>587.587</td>\n",
       "      <td>1.389</td>\n",
       "      <td>0.998</td>\n",
       "      <td>7.574</td>\n",
       "      <td>1.020</td>\n",
       "      <td>13.086</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.161</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14724.395</td>\n",
       "      <td>1547.465</td>\n",
       "      <td>7792.630</td>\n",
       "      <td>113.774</td>\n",
       "      <td>113.774</td>\n",
       "      <td>661.471</td>\n",
       "      <td>288.0</td>\n",
       "      <td>613.851</td>\n",
       "      <td>1.658</td>\n",
       "      <td>0.998</td>\n",
       "      <td>9.007</td>\n",
       "      <td>1.022</td>\n",
       "      <td>18.109</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.140</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21636.432</td>\n",
       "      <td>1924.313</td>\n",
       "      <td>8494.777</td>\n",
       "      <td>175.306</td>\n",
       "      <td>175.306</td>\n",
       "      <td>731.494</td>\n",
       "      <td>288.0</td>\n",
       "      <td>645.642</td>\n",
       "      <td>2.078</td>\n",
       "      <td>0.998</td>\n",
       "      <td>11.197</td>\n",
       "      <td>1.026</td>\n",
       "      <td>26.373</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1          2         3         4        5        6        7   \\\n",
       "0  1.138   3.0    289.964  1349.489  6677.380    7.584    7.584  464.006   \n",
       "1  2.088   6.0   6960.180  1376.166  6828.469   28.204   28.204  635.401   \n",
       "2  3.144   9.0   8379.229  1386.757  7111.811   60.358   60.358  606.002   \n",
       "3  4.161  12.0  14724.395  1547.465  7792.630  113.774  113.774  661.471   \n",
       "4  5.140  15.0  21636.432  1924.313  8494.777  175.306  175.306  731.494   \n",
       "\n",
       "      8        9      10     11      12     13      14     15    16     17  \n",
       "0  288.0  550.563  1.096  0.998   5.947  1.019   7.137  0.082  0.95  0.975  \n",
       "1  288.0  581.658  1.331  0.998   7.282  1.019  10.655  0.287  0.95  0.975  \n",
       "2  288.0  587.587  1.389  0.998   7.574  1.020  13.086  0.259  0.95  0.975  \n",
       "3  288.0  613.851  1.658  0.998   9.007  1.022  18.109  0.358  0.95  0.975  \n",
       "4  288.0  645.642  2.078  0.998  11.197  1.026  26.373  0.522  0.95  0.975  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.txt\", sep='  ', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,:16]\n",
    "y = data.iloc[:,16]\n",
    "\n",
    "x = x.drop(columns = [8,11,6,13])\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "y =y.reshape(len(y), 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+ np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsigmoid(x):\n",
    "    return x*(1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3) #generates a value between 3\n",
    "w0 = np.random.random((12,50)) - 1 #between layers 0 and 1\n",
    "w1 = np.random.random((50,26)) - 1 #between layers 1 and 2\n",
    "w2 = np.random.random((26,12)) - 1\n",
    "w3 = np.random.random((12,1)) - 1\n",
    "\n",
    "b0 = np.random.random((1,1)) - 1\n",
    "b1 = np.random.random((1,1)) - 1\n",
    "b2 = np.random.random((1,1)) - 1\n",
    "b3 = np.random.random((1,1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(data_in , w0, w1 ,w2,w3, b0,b1,b2,b3):\n",
    "    layer0 = data_in\n",
    "    layer1 = sigmoid(np.dot(layer0,w0)+b0)\n",
    "    layer2 = sigmoid(np.dot(layer1,w1)+b1)\n",
    "    layer3 = sigmoid(np.dot(layer2,w2)+b2)\n",
    "    layer4 = np.dot(layer3,w3)+b3\n",
    "    \n",
    "    return layer0,layer1,layer2,layer3,layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propogation(layer0,layer1,layer2,layer3,layer4, actual_y, w0,w1,w2,w3,b0,b1,b2,b3,learning_rate, i):\n",
    "    \n",
    "    l4_error = layer4 - actual_y\n",
    "    l4_delta = l4_error\n",
    "    dh4 = np.dot(layer3.T,l4_delta)\n",
    "    \n",
    "    l3_error = np.dot(l4_delta,w3.T)\n",
    "    l3_delta = l3_error * dsigmoid(layer3)\n",
    "    dh3 = np.dot(layer2.T, l3_delta) #layer 1 change\n",
    "    \n",
    "    l2_error = np.dot(l3_delta,w2.T)\n",
    "    l2_delta = l2_error * dsigmoid(layer2)\n",
    "    dh2 = np.dot(layer1.T,l2_delta)#layer2 changes\n",
    "    \n",
    "    l1_error = np.dot(l2_delta,w1.T)\n",
    "    l1_delta = l1_error * dsigmoid(layer1)\n",
    "    dh1 = np.dot(layer0.T, l1_delta)#layer 3 changes\n",
    "    \n",
    "    w3 = w3 - (learning_rate * dh4)\n",
    "    w2 = w2 - (learning_rate * dh3)\n",
    "    w1 = w1 - (learning_rate * dh2)\n",
    "    w0 = w0 - (learning_rate * dh1)\n",
    "    b3 = b3 - (learning_rate * np.mean(l4_delta))\n",
    "    b2 = b2 - (learning_rate * np.mean(l3_delta))\n",
    "    b1 = b1 - (learning_rate * np.mean(l2_delta))#we use l2_delta as we get a unit value when differentiation with b is done\n",
    "    b0 = b0 - (learning_rate * np.mean(l1_delta))\n",
    "    \n",
    "    if i%1 == 0 and (i!=0):\n",
    "        loss = np.mean(np.power(layer4 - actual_y,2))\n",
    "        loss_curve.append(loss)\n",
    "        iters.append(int(i))\n",
    "        \n",
    "        if i%1000 == 0:\n",
    "            print('\\n', int(i),loss)\n",
    "    \n",
    "    return w0,w1,w2,w3,b0,b1,b2,b3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "loss_curve = []\n",
    "iters = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1000 0.15492029114137065\n",
      "\n",
      " 2000 0.021105605534832494\n",
      "\n",
      " 3000 0.0030330502938013693\n",
      "\n",
      " 4000 0.0005952683544482983\n",
      "\n",
      " 5000 0.0002671562008616107\n",
      "\n",
      " 6000 0.00022307332994178628\n",
      "\n",
      " 7000 0.0002171563430221165\n",
      "\n",
      " 8000 0.000216362466700915\n",
      "\n",
      " 9000 0.0002162559701243401\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    layer0,layer1,layer2,layer3,layer4 = feed_forward(xtrain,w0,w1,w2,w3,b0,b1,b2,b3)\n",
    "    w0,w1,w2,w3,b0,b1,b2,b3 = back_propogation(layer0,layer1,layer2,layer3,layer4,ytrain, w0,w1,w2,w3,b0,b1,b2,b3,0.001,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Loss curve')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iters,loss_curve,\"r.\")\n",
    "plt.xlabel(\"Iters\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"Loss curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01475331304101519"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer0,layer1,layer2,layer3,layer4 = feed_forward(xtest,w0,w1,w2,w3,b0,b1,b2,b3)\n",
    "loss = np.sqrt(np.mean(np.power(layer4-ytest,2)))\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9750261]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = feed_forward(xtest[:1],w0,w1,w2,w3,b0,b1,b2,b3)\n",
    "c[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
